{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e580dc1b-17fe-480f-aaf5-92012b4491d7",
   "metadata": {},
   "source": [
    "# ML Assignment: 1\n",
    "Starting Assignment 1 of Machine Learning, tackling both theoretical concepts and practical questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c2541-8e79-4668-8941-60ff19b29d73",
   "metadata": {},
   "source": [
    "## Theoretical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707dd901-2c7d-4cb3-bc42-621c80e8b7c9",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Compare t-test and z-test in terms of assumptions, population standard deviation, and\n",
    "use case.\n",
    "\n",
    "#### Answer\n",
    "Lets first take a look at both Student's t-score & Normal z-score formula for hypothesis testing:\n",
    "\n",
    "\n",
    "$$ t = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}} $$\n",
    "\n",
    "$$ z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} $$\n",
    "\n",
    "The difference between both of these formulas is between `s`(**sample standard deviation**) and the `σ` (**population standard deviation**).\n",
    "\n",
    "So we could answer the question like this:\n",
    "- Assumptions:\n",
    "- - z-test: Requires known population standard deviation, normally distributed data, and large sample size (n ≥ 30).\n",
    "- - t-test: Uses sample standard deviation, assumes normality (or approximate normality for small n), and is suitable for small samples.\n",
    "- Population Standard Deviation:\n",
    "- - z-test uses the population standard deviation; t-test uses the sample standard deviation.\n",
    "- Use Case:\n",
    "- - Use a z-test for large samples with known population parameters. Use a t-test for small samples or when population parameters are unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbc928e-e432-4334-90c9-e85b662eddfa",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "A tech company is deploying a recommendation system for a music streaming platform.\n",
    "Suppose user ratings for songs (on a scale from 1 to 5) follow a non-normal distribution.\n",
    "If we take a large enough sample, how does CLT justify using a normal approximation\n",
    "for constructing confidence intervals? If the mean predicted rating for a song is 4.2 with\n",
    "a standard deviation of 0.5, how can we use CLT to determine the probability that a\n",
    "randomly selected user will rate the song above 4.5?\n",
    "\n",
    "#### Answer\n",
    "First we must clarify something about Centeral Limit Theorem that might be confusing with out knowing it.\n",
    "\n",
    "- **CLT**:\n",
    "The Central Limit Theorem in Statistics states that as the sample size increases and its variance is finite, then the **distribution of the sample mean approaches normal distribution** irrespective of the shape of the population distribution. [geeksforgeeks reference](https://www.geeksforgeeks.org/central-limit-theorem/)\n",
    "\n",
    "So we could say that the distribution of the **sample mean** approaches normal distribution not any sample from the population.\n",
    "\n",
    "And for the probabilty calculation we must first convert the `X: 4.5` value to the normal `Z` value:\n",
    "\n",
    "for values:\n",
    "$$ \\mu = 4.2 $$\n",
    "$$ \\sigma = 0.5$$\n",
    "$$ z = \\frac{\\bar{X} - \\mu}{\\sigma} = \\frac{4.5 - 4.2}{0.5} = 0.6$$\n",
    "Now we find the probability of Z > 0.6 using the Table from `John E. Freund's Mathematical Statistics`\n",
    "$$P(Z > 0.6) = 1 - 0.7257 = 0.2743$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367bdb94-ec25-4f0a-93ee-5628f0169a8e",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "You are given a dataset containing information about customers in an online retail store.\n",
    "The dataset includes the following features:\n",
    "- Age\n",
    "- Annual Income\n",
    "- Customer Satisfication Score\n",
    "- Preferred Payment Method\n",
    "\n",
    "For each of the following scenarios, determine the most appropriate statistical test from the options: Pearson’s Correlation, Spearman’s Rank Correlation, or Chi-Square Test. Then, apply the test using the dataset provided and interpret the result.\n",
    "\n",
    "#### Tests\n",
    "- **[Pearson's Correlation](https://datatab.net/tutorial/pearson-correlation)** -> Measures the linear relationship between two continuous variables. **Parametric**\n",
    "- **[Spearman’s Rank Correlation](https://datatab.net/tutorial/spearman-correlation)** -> Measures the monotonic relationship between two variables (non-linear trends) **Non-Parametric**.\n",
    "- **[Chi-Square Test](https://datatab.net/tutorial/chi-square-test)** -> Tests the association between categorical variables **Non-Parametric**.\n",
    "\n",
    "#### Parametric Vs Non-Parametric\n",
    "parametric assumes follows a specifc distribution but in non-parametric there is no strict.\n",
    "datatypes in parametric is continues and numerical but in non-parametric is ordinal or categorical.\n",
    "\n",
    "And some more differences but for answering this part we just need these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eca4058-9d17-41ee-9aed-02e3ed540337",
   "metadata": {},
   "source": [
    "#### Scenario (a):\n",
    "The store owner wants to examine whether there is a linear relationship between Age and Annual Income of customers. Which statistical test should be applied? Compute the test statistic and interpret the result.\n",
    "\n",
    "#### Answer\n",
    "Because both Age and Annual Income of customers are continues and we wants to find the linear relationship between these variables based on the comparison that we talked about it earlier we might want to use `Pearson's Correlation`.\n",
    "\n",
    "For the calculations we use some python code for eaiser calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ce3cc67-d7f6-4a19-b6f8-06c9c6fbe7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Annual Income (USD)\n",
       "0   25                40000\n",
       "1   32                55000\n",
       "2   40                65000\n",
       "3   50                70000\n",
       "4   60                85000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's r: 0.98, p-value: 0.0035\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Sample Data in Assignment: \n",
    "data = {\n",
    "    'Age': [25, 32, 40, 50, 60],\n",
    "    'Annual Income (USD)': [40_000, 55_000, 65_000, 70_000, 85_000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "r, p_value = pearsonr(df['Age'], df['Annual Income (USD)'])\n",
    "print(f\"Pearson's r: {r:.2f}, p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac6a3b7-1157-443c-9d05-0b0ff78efed0",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "Based on the high value of `r=0.98` and knowing that Pearson's Correlation is between -1 to 1 we could say that there is strong positive linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7a2b6-fe6e-45f7-b937-8d3c51132f48",
   "metadata": {},
   "source": [
    "#### Scenario (b):\n",
    "The store owner wants to check whether there is a monotonic relationship between\n",
    "Age and Customer Satisfaction Score. Which statistical test should be applied?\n",
    "Compute the test statistic and interpret the result.\n",
    "\n",
    "#### Answer\n",
    "As in the question highlighted that we want to have a monotonic relationship between Age and Customer Satisfaction  Score, we might want to use `Spearman’s Rank Correlation`.\n",
    "\n",
    "For the calculations we use some python code for eaiser calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "244e6dd8-19dc-42f2-9596-ae1500e55c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman's ρ: -0.90, p-value: 0.0374\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Sample Data in Assignment: \n",
    "age = [25, 32, 40, 50, 60]\n",
    "satisfaction = [8, 6, 7, 5, 3]\n",
    "\n",
    "rho, p_value = spearmanr(age, satisfaction)\n",
    "print(f\"Spearman's ρ: {rho:.2f}, p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c214d-dbe9-4bc3-9fe0-618e7b2f90ec",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "Based on the high value of `ρ=-0.90` There is a strong negative correlation between age and satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfad976c-6379-4d8b-b284-f4e4dfb101b9",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "What is the key difference between the Mann-Whitney U test and the Wilcoxon Signed-Rank test? Suppose you are testing two marketing strategies’ effectiveness, but the data is non-normally distributed. Which test would you use?\n",
    "\n",
    "\n",
    "#### Tests\n",
    "- **[Mann-Whitney U test](https://datatab.net/tutorial/mann-whitney-u-test)**: The Mann-Whitney U-Test tests whether there is a difference between two samples. To determine if there is a difference between two samples, the rank sums of the two samples are used rather than the means as in the t-test for **independent samples**. The Mann-Whitney U test is thus the non-parametric counterpart to the t-test.\n",
    "- **[Wilcoxon Signed-Rank test](https://datatab.net/tutorial/wilcoxon-test)**: The Wilcoxon test (Wilcoxon signed-rank test) determines whether two dependent groups differ significantly from each other. To do this, the Wilcoxon test uses the ranks of the groups instead of the mean values. The Wilcoxon test is a non-parametric test, parametric counterpart to the paired samples t-test.\n",
    "\n",
    "\n",
    "#### Comparison\n",
    "1) Both tests are non-parametric alternatives to t-tests, meaning they don’t assume normality.\n",
    "2) Mann-Whitney U Test compares independent groups but the Wilcoxcon Test compares independent groups (like group A is a running test at morning and group B is another running test with same previous group members but at night).\n",
    "3) Both of them use rankings to determine the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27b8273-7551-4dea-a40b-acb74b80d1f9",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "We have collected a dataset with three numerical features and one categorical feature called group. The group feature represents three different experimental conditions (1, 2, or 3). Our goal is to determine whether the groups significantly differ given the numerical feature X.\n",
    "\n",
    "#### Test\n",
    "Before we dive into each scenarios lets take a look at summary of some tests:\n",
    "\n",
    "- **[ANOVA](https://datatab.net/tutorial/anova)**: analysis of variance (ANOVA) tests whether statistically significant differences exist between more than two samples. For this purpose, the means and variances of the respective groups are compared with each other. In contrast to the t-test, which tests between two samples, ANOVA tests between more than two groups. Type of this test is parametric so it assumes the **normally distribution and homogeneity**. Also this test is used for independent groups.\n",
    "- **[Kruskal-Wallis](https://datatab.net/tutorial/kruskal-wallis-test)**: The Kruskal-Wallis test (H test) is a non-parametric statistical test used to compare three or more independent groups to determine if there are statistically significant differences between them. As this test isn't non-parametric **there is no strict to have normally distribution and homogeneity**. Also this test is used for independent groups.\n",
    "- **[Shapiro-Wilk Test]()**: The Shapiro-Wilk test is a hypothesis test that is applied to a sample with a null hypothesis that the sample has been generated from a normal distribution. So might want to use this later on this exercise. We must note that there another tests for normality (e.g. Kolmogorov-Smirnov Test, Anderson-Darling Test) but because there is no restricition to explain them we skip these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6e0f4-282e-43a9-9375-e77a7c118d9b",
   "metadata": {},
   "source": [
    "#### Scenario (a)\n",
    "We want to see whether the groups differ given this feature X or not. Now, we should choose between these two tests (ANOVA or Kruskal-Wallis). In your opinion, what should we check (test) to help us choose between these two tests And once you have made your choice, apply your test. (Consider P-Value less than 0.05.)\n",
    "\n",
    "#### Answer\n",
    "So the question says we must to check there is difference or not, and we have two options called ANOVA & Kruskal-Wallis. With the previous summary we know that their bigest differnce is that ANOVA is parametric (assume normality & homogeneity) and Kruskal-Wallis is non-parametric, so we take a Shapiro-Wilk Test on this sample to check which test we must use.\n",
    "\n",
    "We use some python packages for have easier calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2f6e7e2d-c671-49da-a041-4bb5bc2faa3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality p-values: 0.048, 0.891, 0.387\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "feature_x = [10.2, 10.8, 11.0, 18.5, 17.9, 18.2, 30.1, 29.8, 30.3]\n",
    "feature_y = [7.8, 8.1, 7.5, 6.9, 7.3, 6.8, 6.2, 6.5, 6.0]\n",
    "feature_z = [5.4, 5.2, 5.8, 6.2, 6.0, 5.9, 7.0, 7.1, 6.9]\n",
    "\n",
    "# Shapiro-Wilk test for normality\n",
    "_, p1 = shapiro(feature_x)\n",
    "_, p2 = shapiro(feature_y)\n",
    "_, p3 = shapiro(feature_z)\n",
    "\n",
    "print(f\"Normality p-values: {p1:.3f}, {p2:.3f}, {p3:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacf4aa3-5dee-472e-9e74-42859819b1a3",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "Since the p-value for feature_x (Group 1) is less than 0.05, this indicates a rejection of the normality assumption for that group. When even one group deviates from normality, the validity of the ANOVA test becomes questionable.\n",
    "\n",
    "Therefore, the non-parametric `Kruskal-Wallis` test is more appropriate in this scenario because it does not assume normality of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf8760-610e-4057-8097-10fc490f108f",
   "metadata": {},
   "source": [
    "#### Scenario (b)\n",
    "Based on the result of (a), apply the appropriate Statistical Test (ANOVA or\n",
    "Kruskal-Wallis) to determine if there is a significant difference between the groups.\n",
    "Which one would you use and why?\n",
    "\n",
    "\n",
    "#### Answer \n",
    "Answer of this question is in the previous answer and with those that in mind we use Kruskal-Wallis test and use some python packages for easier calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7522ef1-5168-4552-972a-32a7db007609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis p-value: 0.0001\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "feature_x = [10.2, 10.8, 11.0, 18.5, 17.9, 18.2, 30.1, 29.8, 30.3]\n",
    "feature_y = [7.8, 8.1, 7.5, 6.9, 7.3, 6.8, 6.2, 6.5, 6.0]\n",
    "feature_z = [5.4, 5.2, 5.8, 6.2, 6.0, 5.9, 7.0, 7.1, 6.9]\n",
    "\n",
    "h_stat, p_kruskal = kruskal(feature_x, feature_y, feature_z)\n",
    "print(f\"Kruskal-Wallis p-value: {p_kruskal:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c5eb1-385b-4bb6-9f4e-048d32ea5846",
   "metadata": {},
   "source": [
    "#### Interpretation \n",
    "Since the p-value (0.0001) is less than the significance level of 0.05, we conclude that there is a statistically significant difference between the groups for the numerical feature X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef150d4-e0e3-427c-82e3-5db6419ea2ec",
   "metadata": {},
   "source": [
    "#### Scenario (c)\n",
    "Assume the normality assumption holds. If you wanted to check whether the groups\n",
    "also significantlly differ given all three features (X, Y and Z), what statistical test\n",
    "could have been used?\n",
    "\n",
    "#### Answer\n",
    "When we have multiple continuous dependent variables (in this case, X, Y, and Z) and a single categorical independent variable (the groups), and the assumption of normality holds, you would typically use Multivariate Analysis of Variance (**[MANOVA](https://www.ibm.com/docs/sl/spss-statistics/beta?topic=statistics-multivariate-analysis-variance-manova)**).\n",
    "\n",
    "MANOVA tests whether the mean vectors of the dependent variables differ across the groups. It is particularly useful when the dependent variables might be correlated, as it accounts for their interrelationships while testing for overall group differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7d5698-351d-4286-957e-a5a0510201d9",
   "metadata": {},
   "source": [
    "#### Scenario (c)\n",
    "For feature selection, you can apply ANOVA or Kruskal-Wallis to each feature individually to test if its distribution significantly differs across groups. If a feature yields a p-value below 0.05, it suggests that the feature varies across groups and may be a useful predictor. Use ANOVA when the data are normally distributed, or Kruskal-Wallis when the normality assumption is violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f39787ac-6be6-418d-836f-db2b3e6246f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results:\n",
      "Feature X: p-value = 0.0000\n",
      "Feature Y: p-value = 0.0013\n",
      "Feature Z: p-value = 0.0003\n",
      "\n",
      "Kruskal-Wallis results:\n",
      "Feature X: p-value = 0.0273\n",
      "Feature Y: p-value = 0.0273\n",
      "Feature Z: p-value = 0.0273\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway, kruskal\n",
    "\n",
    "# Sample dataset with a 'group' column and three features X, Y, and Z\n",
    "data = {\n",
    "    'group': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "    'X': [10.2, 10.8, 11.0, 18.5, 17.9, 18.2, 30.1, 29.8, 30.3],\n",
    "    'Y': [7.8, 8.1, 7.5, 6.9, 7.3, 6.8, 6.2, 6.5, 6.0],\n",
    "    'Z': [5.4, 5.2, 5.8, 6.2, 6.0, 5.9, 7.0, 7.1, 6.9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "groups = df['group'].unique()\n",
    "\n",
    "print(\"ANOVA results:\")\n",
    "for feature in ['X', 'Y', 'Z']:\n",
    "    group_data = [df[df['group'] == g][feature].values for g in groups]\n",
    "    stat, p = f_oneway(*group_data)\n",
    "    print(f\"Feature {feature}: p-value = {p:.4f}\")\n",
    "\n",
    "print(\"\\nKruskal-Wallis results:\")\n",
    "for feature in ['X', 'Y', 'Z']:\n",
    "    group_data = [df[df['group'] == g][feature].values for g in groups]\n",
    "    stat, p = kruskal(*group_data)\n",
    "    print(f\"Feature {feature}: p-value = {p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047ad69-386f-4194-8706-d99a0ad48306",
   "metadata": {},
   "source": [
    "#### Interpretation \n",
    "Both tests confirm that features X, Y, and Z are significant in differentiating the groups. These test supports the conclusion that these features are useful for predicting group membership."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
